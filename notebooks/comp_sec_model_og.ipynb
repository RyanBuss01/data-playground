{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21fe0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preproccess\n",
    "import pandas as pd \n",
    "import os \n",
    "import glob \n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd747cd5e5c1faa7",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_path = '/datasets/CICIoT2023/'          # If your dataset is within your python project directory, change this to the relative path to your dataset\n",
    "path = os.getcwd() + rel_path   # If your dataset is somewhere else, change this to that path\n",
    "csv_filepaths = glob.glob(os.path.join(path, \"*.csv\"))  # Makes a list of all CSVs within the directory above\n",
    "\n",
    "# Features that hold values 0/1.\n",
    "column_datatypes = { 'fin_flag_number': 'bool', 'syn_flag_number': 'bool', 'rst_flag_number': 'bool',\n",
    "                     'psh_flag_number': 'bool', 'ack_flag_number': 'bool', 'ece_flag_number': 'bool',\n",
    "                     'cwr_flag_number': 'bool', \n",
    "                     'HTTP': 'bool', 'HTTPS': 'bool', 'DNS': 'bool', 'Telnet': 'bool', 'SMTP': 'bool',\n",
    "                     'SSH': 'bool',  'IRC': 'bool',   'TCP': 'bool', 'UDP': 'bool',    'DHCP': 'bool',\n",
    "                     'ARP': 'bool',  'ICMP': 'bool',  'IPv': 'bool', 'LLC': 'bool'\n",
    "                   }\n",
    "\n",
    "# Load the first csv file\n",
    "df = pd.read_csv(csv_filepaths[0]).astype(column_datatypes)\n",
    "\n",
    "# Load csv files in 10-file batches \n",
    "batch_size = 10\n",
    "\n",
    "for i in range(1, len(csv_filepaths)):\n",
    "    clear_output(wait=False) # Pretty output\n",
    "    print(f'Loading CSV {i}')\n",
    "    \n",
    "    # First file of each batch, restart the batch list\n",
    "    if i % batch_size == 1:\n",
    "        batch = [df]\n",
    "    \n",
    "    batch.append(pd.read_csv(csv_filepaths[i]).astype(column_datatypes))    # Load a CSV and change relevant columns to bools\n",
    "    \n",
    "    # every #batch_size# file, add it to the df dataframe\n",
    "    if i % batch_size == 0:\n",
    "        df = pd.concat(batch)\n",
    "        batch.clear()   # Get rid of old batch files to free memory\n",
    "        print(f'Loaded to {i}')\n",
    "\n",
    "# Load any remaining data in batch\n",
    "if len(batch) != 0:\n",
    "    print(\"Loading data from final batch.\")\n",
    "    df = pd.concat(batch)\n",
    "\n",
    "clear_output(wait=False)\n",
    "del batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b9381ca755f0e",
   "metadata": {},
   "source": [
    "# Dataframe Memory Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4091a5b4ec03ce77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:34:12.337527Z",
     "start_time": "2024-04-09T20:34:12.316846Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.064719223 gb\n"
     ]
    }
   ],
   "source": [
    "tot_mem = df.memory_usage().sum()\n",
    "print(f'{tot_mem / 1000000000} gb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa3be162d401c0b",
   "metadata": {},
   "source": [
    "# Encoding labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e92bde5853b8a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:34:52.717209Z",
     "start_time": "2024-04-09T20:34:31.941575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>Drate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037456</td>\n",
       "      <td>15099.00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>10001.102371</td>\n",
       "      <td>10001.102371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.310215e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.333177e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010346</td>\n",
       "      <td>9662.50</td>\n",
       "      <td>17.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21380.056228</td>\n",
       "      <td>21380.056228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.309879e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>241.333973</td>\n",
       "      <td>241.333973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.295112e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.195109</td>\n",
       "      <td>95.58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6.762174</td>\n",
       "      <td>6.762174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.336540e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224084</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.305208</td>\n",
       "      <td>12.305208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.334406e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224085</th>\n",
       "      <td>0.260599</td>\n",
       "      <td>195.28</td>\n",
       "      <td>17.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.019235</td>\n",
       "      <td>5.019235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6.256217</td>\n",
       "      <td>91.6</td>\n",
       "      <td>8.300770e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>13.225017</td>\n",
       "      <td>8.802365</td>\n",
       "      <td>287.083940</td>\n",
       "      <td>0.14</td>\n",
       "      <td>141.55</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224086</th>\n",
       "      <td>59.963741</td>\n",
       "      <td>67179.40</td>\n",
       "      <td>12.0</td>\n",
       "      <td>102.8</td>\n",
       "      <td>5.632240</td>\n",
       "      <td>5.632240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>66.941103</td>\n",
       "      <td>160.3</td>\n",
       "      <td>1.665198e+08</td>\n",
       "      <td>13.5</td>\n",
       "      <td>14.871934</td>\n",
       "      <td>94.837019</td>\n",
       "      <td>4892.474222</td>\n",
       "      <td>1.00</td>\n",
       "      <td>244.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224087</th>\n",
       "      <td>0.537183</td>\n",
       "      <td>85.86</td>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.198275</td>\n",
       "      <td>2.198275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.336535e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224088</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.930168</td>\n",
       "      <td>0.930168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.333096e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46686579 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\n",
       "0            0.037456       15099.00           17.0      64.0  10001.102371   \n",
       "1            0.000000          54.00            6.0      64.0      0.000000   \n",
       "2            0.010346        9662.50           17.0      64.0  21380.056228   \n",
       "3            0.000000          54.00            6.0      64.0    241.333973   \n",
       "4            0.195109          95.58            6.0      64.0      6.762174   \n",
       "...               ...            ...            ...       ...           ...   \n",
       "224084       0.000000          54.00            6.0      64.0     12.305208   \n",
       "224085       0.260599         195.28           17.0      64.0      5.019235   \n",
       "224086      59.963741       67179.40           12.0     102.8      5.632240   \n",
       "224087       0.537183          85.86            6.0      64.0      2.198275   \n",
       "224088       0.000000          54.00            6.0      64.0      0.930168   \n",
       "\n",
       "               Srate  Drate  fin_flag_number  syn_flag_number  \\\n",
       "0       10001.102371    0.0            False            False   \n",
       "1           0.000000    0.0            False            False   \n",
       "2       21380.056228    0.0            False            False   \n",
       "3         241.333973    0.0            False            False   \n",
       "4           6.762174    0.0            False             True   \n",
       "...              ...    ...              ...              ...   \n",
       "224084     12.305208    0.0             True            False   \n",
       "224085      5.019235    0.0            False            False   \n",
       "224086      5.632240    0.0            False            False   \n",
       "224087      2.198275    0.0            False             True   \n",
       "224088      0.930168    0.0            False            False   \n",
       "\n",
       "        rst_flag_number  ...        Std  Tot size           IAT  Number  \\\n",
       "0                 False  ...   0.000000      50.0  8.310215e+07     9.5   \n",
       "1                 False  ...   0.000000      54.0  8.333177e+07     9.5   \n",
       "2                 False  ...   0.000000      50.0  8.309879e+07     9.5   \n",
       "3                 False  ...   0.000000      54.0  8.295112e+07     9.5   \n",
       "4                 False  ...   0.000000      54.0  8.336540e+07     9.5   \n",
       "...                 ...  ...        ...       ...           ...     ...   \n",
       "224084             True  ...   0.000000      54.0  8.334406e+07     9.5   \n",
       "224085            False  ...   6.256217      91.6  8.300770e+07     9.5   \n",
       "224086            False  ...  66.941103     160.3  1.665198e+08    13.5   \n",
       "224087            False  ...   0.000000      54.0  8.336535e+07     9.5   \n",
       "224088            False  ...   0.000000      54.0  8.333096e+07     9.5   \n",
       "\n",
       "         Magnitue     Radius   Covariance  Variance  Weight  label  \n",
       "0       10.000000   0.000000     0.000000      0.00  141.55     14  \n",
       "1       10.392305   0.000000     0.000000      0.00  141.55      8  \n",
       "2       10.000000   0.000000     0.000000      0.00  141.55     14  \n",
       "3       10.392305   0.000000     0.000000      0.00  141.55     20  \n",
       "4       10.392305   0.000000     0.000000      0.00  141.55     12  \n",
       "...           ...        ...          ...       ...     ...    ...  \n",
       "224084  10.392305   0.000000     0.000000      0.00  141.55      9  \n",
       "224085  13.225017   8.802365   287.083940      0.14  141.55     21  \n",
       "224086  14.871934  94.837019  4892.474222      1.00  244.60      1  \n",
       "224087  10.392305   0.000000     0.000000      0.00  141.55     12  \n",
       "224088  10.392305   0.000000     0.000000      0.00  141.55      8  \n",
       "\n",
       "[46686579 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_maps = { 'Backdoor_Malware': '0',         'BenignTraffic': '1',           'BrowserHijacking': '2',\n",
    "               'CommandInjection': '3',         'DDoS-ACK_Fragmentation': '4',  'DDoS-HTTP_Flood': '5',\n",
    "               'DDoS-ICMP_Flood': '6',          'DDoS-ICMP_Fragmentation': '7', 'DDoS-PSHACK_Flood': '8',\n",
    "               'DDoS-RSTFINFlood': '9',         'DDoS-SYN_Flood': '10',         'DDoS-SlowLoris': '11',\n",
    "               'DDoS-SynonymousIP_Flood': '12', 'DDoS-TCP_Flood': '13',         'DDoS-UDP_Flood': '14',\n",
    "               'DDoS-UDP_Fragmentation': '15',  'DNS_Spoofing': '16',           'DictionaryBruteForce': '17',\n",
    "               'DoS-HTTP_Flood': '18',          'DoS-SYN_Flood': '19',          'DoS-TCP_Flood': '20',\n",
    "               'DoS-UDP_Flood': '21',           'MITM-ArpSpoofing': '22',       'Mirai-greeth_flood': '23',\n",
    "               'Mirai-greip_flood': '24',       'Mirai-udpplain': '25',         'Recon-HostDiscovery': '26',\n",
    "               'Recon-OSScan': '27',            'Recon-PingSweep': '28',        'Recon-PortScan': '29',\n",
    "               'SqlInjection': '30',            'Uploading_Attack': '31',       'VulnerabilityScan': '32', \n",
    "               'XSS': '33'\n",
    "             }\n",
    "\n",
    "df['label'] = df['label'].map(label_maps)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f993b5c0",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e59a6",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ad5da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the initial layer of the generator\n",
    "input_shape = 47\n",
    "num_epochs = 2\n",
    "batch_size = 256 # Define your batch size here\n",
    "num_samples = 100\n",
    "epochs = 7000\n",
    "critic_updates = 5  # Number of critic updates per generator update\n",
    "attack_classes = [\"DDoS\",\"DoS\",\"Recon\",\"Brute Force\", \"Web-Based\", \"Spoofing\", \"Mirai\"]\n",
    "num_classes = len(attack_classes)\n",
    "\n",
    "result = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740466df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN class\n",
    "# This class contains the generator and discriminator models, as well as the training loop for the GAN\n",
    "class GAN:\n",
    "    def __init__(self, hidden1, hidden2, hidden3, layer0_num_neurons, num_classes):\n",
    "        # store the parameters as instance variables\n",
    "        self.hidden1 = hidden1\n",
    "        self.hidden2 = hidden2\n",
    "        self.hidden3 = hidden3\n",
    "        self.layer0_num_neurons = layer0_num_neurons\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # build the generator and discriminator\n",
    "        self.generator = self.build_generator(self.hidden1, self.hidden2, self.hidden3, self.layer0_num_neurons)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "\n",
    "        # compile the generator and discriminator\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        self.generator.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "        self.discriminator.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    def build_generator(self, hidden1, hidden2, hidden3, input_dim):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(hidden1, input_dim=input_dim))  \n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(hidden2))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(hidden3))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(input_dim, activation='relu'))  # Changed from output_dim to input_dim\n",
    "\n",
    "        noise = Input(shape=(input_dim,))\n",
    "        attack = model(noise)\n",
    "        return Model(noise, attack)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(input_shape, input_dim=input_shape, activation='relu'))  \n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(15, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "        attack = Input(shape=(input_shape,))\n",
    "        validity = model(attack)\n",
    "\n",
    "        return Model(attack, validity)\n",
    "    \n",
    "    # define baseline model\n",
    "    def baseline_model():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        inputs = input_shape\n",
    "        hidden_layer1 = 10\n",
    "        hidden_layer2 = 5\n",
    "        hidden_layer3 = 0\n",
    "        outputs = num_classes  #needs to be this variable in case we forget to sample. Could end up having 10 classes or 12, etc\n",
    "        \n",
    "        model.add(Dense(hidden_layer1, input_dim=inputs, activation='relu'))\n",
    "        if hidden_layer2 != 0:\n",
    "            model.add(Dense(hidden_layer2, activation='relu'))\n",
    "        if hidden_layer3 != 0:\n",
    "            model.add(Dense(hidden_layer3, activation='relu'))\n",
    "        model.add(Dense(outputs, activation='softmax'))\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #optimizer=adam\n",
    "        return model\n",
    "    \n",
    "   \n",
    "    def discriminator_loss(self, real_output, fake_output):\n",
    "        return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "    def generator_loss(self, fake_output):\n",
    "        return -tf.reduce_mean(fake_output)\n",
    "\n",
    "\n",
    "    def trainGAN(self, gen_hidden1, gen_hidden2, gen_hidden3, input_dim):\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        # Directly use 'result' DataFrame. Ensure it's accessible within this scope.\n",
    "        # Sampling 500 data points randomly from 'result'\n",
    "        sampled_df = result.sample(500)\n",
    "\n",
    "\n",
    "        # Splitting the data into features and labels\n",
    "        X_train = sampled_df.values.astype(float)\n",
    "        Y_train = sampled_df['label'].values\n",
    "\n",
    "        # Setting up labels for valid (real) and fake data for training\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Building the discriminator\n",
    "        discriminator = self.build_discriminator()\n",
    "        discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Building the generator\n",
    "        generator = self.build_generator(gen_hidden1, gen_hidden2, gen_hidden3, input_dim)\n",
    "\n",
    "        # Setting up the combined model\n",
    "        z = Input(shape=(input_shape,))\n",
    "        attack = generator(z)\n",
    "        validity = discriminator(attack)\n",
    "        combined = Model(z, validity)\n",
    "        combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            clear_output(wait=False)\n",
    "            # Train Discriminator\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_attacks = X_train[idx]\n",
    "\n",
    "            noise = tf.random.normal((batch_size, input_shape))\n",
    "            gen_attacks = generator.predict(noise)\n",
    "\n",
    "            d_loss_real = discriminator.train_on_batch(real_attacks, valid)\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_attacks, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Train Generator\n",
    "            g_loss = combined.train_on_batch(noise, valid)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}%] [G loss: {g_loss}]\")\n",
    "\n",
    "            # if our generator loss icreased this iteration, increment the counter by 1\n",
    "            if (g_loss - prev_g_loss) > 0:\n",
    "                loss_increase_count = loss_increase_count + 1\n",
    "            else: \n",
    "                loss_increase_count = 0  # otherwise, reset it to 0, we are still training effectively\n",
    "                \n",
    "            prev_g_loss = g_loss\n",
    "                \n",
    "            if loss_increase_count > 5:\n",
    "                print('Stoping on iteration: ', epoch)\n",
    "                break\n",
    "                \n",
    "            if epoch % 20 == 0:\n",
    "                f = open(\"Results/GANresultsportsweep.txt\", \"a\")\n",
    "                np.savetxt(\"Results/GANresultsportsweep.txt\", gen_attacks, fmt=\"%.0f\")\n",
    "                f.close()\n",
    "\n",
    "        # peek at our results\n",
    "        results = np.loadtxt(\"Results/GANresultsportsweep.txt\")\n",
    "        print(\"Generated portsweep attacks: \")\n",
    "        print(results[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14fad6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers:  51 11 74\n"
     ]
    }
   ],
   "source": [
    "# Randomly select hidden layer sizes for the generator\n",
    "gen_hidden1 = np.random.randint(1, 101)\n",
    "gen_hidden2 = np.random.randint(1, 101)\n",
    "gen_hidden3 = np.random.randint(1, 101)\n",
    "\n",
    "# Create the GAN with the selected hidden layer sizes\n",
    "gan = GAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape, num_classes)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Hidden Layers: \", gen_hidden1, gen_hidden2, gen_hidden3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bdfdaa",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4639bbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GAN with hidden layers:  51 11 74\n",
      "Training Complete in 322.37 seconds!!!\n"
     ]
    }
   ],
   "source": [
    "# Call the trainGAN function directly to start training\n",
    "print(\"Training GAN with hidden layers: \", gen_hidden1, gen_hidden2, gen_hidden3)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "gan.trainGAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"Training GAN with hidden layers: \", gen_hidden1, gen_hidden2, gen_hidden3)\n",
    "print(\"Training Complete in {:.2f} seconds!!!\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3896d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracies()  :\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    for i in range(100) :\n",
    "        # Generate samples from the trained generator\n",
    "        noise = tf.random.normal((num_samples, input_shape))\n",
    "        generated_samples = gan.generator(noise)\n",
    "\n",
    "        # Pass the generated samples through the discriminator\n",
    "        discriminator_predictions = gan.discriminator.predict(generated_samples)\n",
    "\n",
    "        # The ideal output for generated samples is 1\n",
    "        ideal_output = np.ones((num_samples,))\n",
    "\n",
    "        # Correcting the prediction rounding\n",
    "        discriminator_predictions_rounded = np.round(discriminator_predictions).flatten()\n",
    "\n",
    "        # Now, calculating the accuracy should not throw an error\n",
    "        accuracy = accuracy_score(ideal_output, discriminator_predictions_rounded)\n",
    "        f1 = f1_score(ideal_output, discriminator_predictions_rounded)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    accuracy = np.mean(accuracy_scores)\n",
    "    f1 = np.mean(f1_scores)\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2152f39",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "871d0d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.92\n",
      "F1 Score:  0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "accuracy,f1 = getAccuracies()\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc8f83",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ee929",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_save_path = \"../model/comp_sec/generator\"\n",
    "discriminator_save_path = \"../model/comp_sec/discriminator\"\n",
    "\n",
    "# Save the generator\n",
    "gan.generator.save(generator_save_path)\n",
    "# Save the discriminator\n",
    "gan.discriminator.save(discriminator_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea832e",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252763d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_load_path = \"../model/comp_sec/generator\"\n",
    "discriminator_load_path = \"../model/comp_sec/discriminator\"\n",
    "\n",
    "gan.generator = load_model(generator_load_path)\n",
    "gan.discriminator = load_model(discriminator_load_path)\n",
    "\n",
    "gan.generator.summary()\n",
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f737d",
   "metadata": {},
   "source": [
    "### Best Model Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16f717",
   "metadata": {},
   "source": [
    "Will continue to run until a better model is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0691cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Looper:\n",
    "    def random_numbers():\n",
    "        gen_hidden1 = np.random.randint(1, 101)\n",
    "        gen_hidden2 = np.random.randint(1, 101)\n",
    "        gen_hidden3 = np.random.randint(1, 101)\n",
    "        return [gen_hidden1, gen_hidden2, gen_hidden3]\n",
    "    \n",
    "    def evaluate(gan):\n",
    "        noise = tf.random.normal((num_samples, input_shape))\n",
    "        generated_samples = gan.generator(noise)\n",
    "        discriminator_predictions = gan.discriminator.predict(generated_samples)\n",
    "        ideal_output = np.ones((num_samples,))\n",
    "        discriminator_predictions_rounded = np.round(discriminator_predictions).flatten()\n",
    "        ideal_output = np.ones((num_samples,))\n",
    "        accuracy = accuracy_score(ideal_output, discriminator_predictions_rounded)\n",
    "        f1 = f1_score(ideal_output, discriminator_predictions_rounded)\n",
    "        return accuracy, f1\n",
    "    \n",
    "    def save(gan):\n",
    "        generator_save_path = \"model/best_generator\"\n",
    "        discriminator_save_path = \"model/best_discriminator\"\n",
    "        gan.generator.save(generator_save_path)\n",
    "        gan.discriminator.save(discriminator_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gan is None:\n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "else:\n",
    "    best_accuracy, best_f1 = Looper.evaluate(gan)\n",
    "\n",
    "while (True):\n",
    "    # Randomly select hidden layer sizes for the generator\n",
    "    [gen_hidden1, gen_hidden2, gen_hidden3] = Looper.random_numbers()\n",
    "\n",
    "    # Create the GAN with the selected hidden layer sizes\n",
    "    gan = GAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape, num_classes)\n",
    "    # Call the trainGAN function directly to start training\n",
    "    gan.trainGAN(gen_hidden1, gen_hidden2, gen_hidden3, input_shape)\n",
    "    accuracy, f1 = getAccuracies(gan)   \n",
    "    print(\"Accuracy: \", accuracy, \"F1 Score: \", f1, \"Hidden Layers: \", gen_hidden1, gen_hidden2, gen_hidden3)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_f1 = f1\n",
    "        Looper.save(gan)\n",
    "        print(\"Saved New Model\")\n",
    "        break\n",
    "    \n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"Accuracy: \", best_accuracy, \"F1 Score: \", best_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
