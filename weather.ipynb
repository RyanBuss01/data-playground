{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import tensorflow as tf\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://api.oikolab.com/weather\"\n",
    "response = requests.get(url,\n",
    "    params={'param': 'temperature',\n",
    "            'location': 'Toronto, Ontario',\n",
    "            'start': '1990-01-01',\n",
    "            'end': '2020-12-31'},\n",
    "    headers={'api-key': api_key}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 400 {\n",
      "  \"title\": \"The requested data volume exceeds remaining balance of free units.\",\n",
      "  \"description\": \"Please add credit card information to continue using the service.\",\n",
      "  \"link\": {\n",
      "    \"text\": \"Documentation related to this error\",\n",
      "    \"href\": \"https://docs.oikolab.com/references\",\n",
      "    \"rel\": \"help\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print('Success:', response.text)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/data.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(\u001b[43mdata\u001b[49m, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "with open('data/data.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data.json', 'r') as f:\n",
    "    js = json.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       coordinates (lat,lon) model (name)  \\\n",
      "1990-01-01 00:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 01:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 02:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 03:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 04:00:00  (43.653482, -79.383935)         era5   \n",
      "\n",
      "                     model elevation (surface)  utc_offset (hrs)  \\\n",
      "1990-01-01 00:00:00                     127.19              -5.0   \n",
      "1990-01-01 01:00:00                     127.19              -5.0   \n",
      "1990-01-01 02:00:00                     127.19              -5.0   \n",
      "1990-01-01 03:00:00                     127.19              -5.0   \n",
      "1990-01-01 04:00:00                     127.19              -5.0   \n",
      "\n",
      "                     temperature (degC)  \n",
      "1990-01-01 00:00:00                2.37  \n",
      "1990-01-01 01:00:00                2.07  \n",
      "1990-01-01 02:00:00                1.82  \n",
      "1990-01-01 03:00:00                1.13  \n",
      "1990-01-01 04:00:00                0.92  \n"
     ]
    }
   ],
   "source": [
    "data = json.loads(js['data'])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(index=pd.to_datetime(data['index'], unit='s'),\n",
    "                  data=data['data'],\n",
    "                  columns=data['columns'])\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the temperature to fahrenheit\n",
    "df['temperature (degF)'] = df['temperature (degC)'] * 9/5 + 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "temperature_scaled = scaler.fit_transform(df[['temperature (degF)']].values)\n",
    "window_size = 24 * 7  # Number of past days to use for predicting the next day's temperature\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(temperatures, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(temperatures) - window_size):\n",
    "        X.append(temperatures[i:i + window_size])\n",
    "        y.append(temperatures[i + window_size])\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Use the normalized temperature data for creating sequences\n",
    "X, y = create_sequences(temperature_scaled, window_size)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# It's important not to shuffle time series data to maintain the temporal sequence\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the model if necessary\n",
    "model = Sequential([\n",
    "    LSTM(100, activation='relu', input_shape=(X.shape[1], X.shape[2])),  # Increased complexity\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 15:58:39.852649: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5432/5432 [==============================] - 302s 55ms/step - loss: 0.0014 - val_loss: 1.3561e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28dc07410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m latest_data \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature (degF)\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues)[\u001b[38;5;241m-\u001b[39mwindow_size:]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, window_size, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m predicted_temperatures_normalized \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Recursive prediction\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "latest_data = scaler.transform(df[['temperature (degF)']].values)[-window_size:].reshape((1, window_size, 1))\n",
    "predicted_temperatures_normalized = []\n",
    "\n",
    "# Recursive prediction\n",
    "for _ in range(window_size):\n",
    "    # Predict the next step\n",
    "    next_step_normalized = model.predict(latest_data)\n",
    "    \n",
    "    # Store the normalized prediction\n",
    "    predicted_temperatures_normalized.append(next_step_normalized[0, 0])\n",
    "    \n",
    "    # Update the input sequence with the new prediction\n",
    "    # This moves the window one step forward by inserting the predicted value\n",
    "    latest_data = np.roll(latest_data, -1, axis=1)\n",
    "    latest_data[0, -1, 0] = next_step_normalized[0, 0]\n",
    "\n",
    "# Convert normalized predictions back to the original scale (degrees Fahrenheit)\n",
    "predicted_temperatures = scaler.inverse_transform(np.array(predicted_temperatures_normalized).reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"Predicted temperatures for the next 7 days (168 hours):\")\n",
    "print(predicted_temperatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 20:34:50.872465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.876265: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.913531: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node lstm_12_input}}]]\n",
      "2024-03-16 20:34:50.945406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node lstm_12_input}}]]\n",
      "2024-03-16 20:34:50.950729: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.955439: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node lstm_12_input}}]]\n",
      "2024-03-16 20:34:50.959664: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.964056: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node lstm_12_input}}]]\n",
      "2024-03-16 20:34:50.967521: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.970409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.976395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.980155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:51.002057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node lstm_12_input}}]]\n",
      "2024-03-16 20:34:51.008475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:51.011973: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:51.071874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2024-03-16 20:34:51.075514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2024-03-16 20:34:51.078660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:51.082115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:51.230148: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node serving_default_lstm_12_input}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/tempModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/tempModel/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model/tempModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x290bf0bd0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model('model/tempModel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
