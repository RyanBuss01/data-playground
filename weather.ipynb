{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://api.oikolab.com/weather\"\n",
    "response = requests.get(url,\n",
    "    params={'param': 'temperature',\n",
    "            'location': 'Toronto, Ontario',\n",
    "            'start': '1990-01-01',\n",
    "            'end': '2020-12-31'},\n",
    "    headers={'api-key': api_key}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print('Success:', response.text)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data.json', 'r') as f:\n",
    "    js = json.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       coordinates (lat,lon) model (name)  \\\n",
      "1990-01-01 00:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 01:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 02:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 03:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 04:00:00  (43.653482, -79.383935)         era5   \n",
      "\n",
      "                     model elevation (surface)  utc_offset (hrs)  \\\n",
      "1990-01-01 00:00:00                     127.19              -5.0   \n",
      "1990-01-01 01:00:00                     127.19              -5.0   \n",
      "1990-01-01 02:00:00                     127.19              -5.0   \n",
      "1990-01-01 03:00:00                     127.19              -5.0   \n",
      "1990-01-01 04:00:00                     127.19              -5.0   \n",
      "\n",
      "                     temperature (degC)  \n",
      "1990-01-01 00:00:00                2.37  \n",
      "1990-01-01 01:00:00                2.07  \n",
      "1990-01-01 02:00:00                1.82  \n",
      "1990-01-01 03:00:00                1.13  \n",
      "1990-01-01 04:00:00                0.92  \n"
     ]
    }
   ],
   "source": [
    "data = json.loads(js['data'])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(index=pd.to_datetime(data['index'], unit='s'),\n",
    "                  data=data['data'],\n",
    "                  columns=data['columns'])\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the temperature to fahrenheit\n",
    "df['temperature (degF)'] = df['temperature (degC)'] * 9/5 + 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "temperature_scaled = scaler.fit_transform(df[['temperature (degF)']].values)\n",
    "window_size = 24 * 7  # Number of past days to use for predicting the next day's temperature\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(temperatures, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(temperatures) - window_size):\n",
    "        X.append(temperatures[i:i + window_size])\n",
    "        y.append(temperatures[i + window_size])\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Use the normalized temperature data for creating sequences\n",
    "X, y = create_sequences(temperature_scaled, window_size)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# It's important not to shuffle time series data to maintain the temporal sequence\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the model if necessary\n",
    "model = Sequential([\n",
    "    LSTM(100, activation='relu', input_shape=(X.shape[1], X.shape[2])),  # Increased complexity\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5432/5432 [==============================] - 1151s 212ms/step - loss: 0.0017 - val_loss: 1.6196e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14f966a90>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Predicted temperatures for the next 7 days (168 hours):\n",
      "[33.830128 33.00379  32.32623  31.78369  31.380579 31.115358 30.979052\n",
      " 30.956306 31.0271   31.16856  31.35685  31.568827 31.783485 31.98291\n",
      " 32.15301  32.283886 32.369747 32.408726 32.40236  32.35497  32.272964\n",
      " 32.164104 32.036743 31.899246 31.759409 31.62404  31.498644 31.387327\n",
      " 31.292631 31.215715 31.156408 31.11343  31.084719 31.067577 31.058996\n",
      " 31.055933 31.05542  31.054853 31.052011 31.045218 31.033308 31.015661\n",
      " 30.992146 30.963062 30.929018 30.890905 30.849743 30.8066   30.762554\n",
      " 30.718565 30.67545  30.6339   30.594358 30.557112 30.522247 30.489716\n",
      " 30.459309 30.430721 30.403595 30.37754  30.35216  30.327085 30.301989\n",
      " 30.276604 30.25074  30.224247 30.197102 30.169254 30.140808 30.111826\n",
      " 30.082441 30.052778 30.023003 29.993221 29.963589 29.934189 29.905107\n",
      " 29.876394 29.848095 29.820217 29.79273  29.765621 29.738848 29.71237\n",
      " 29.686121 29.660059 29.63415  29.608332 29.582592 29.5569   29.531242\n",
      " 29.505606 29.480019 29.45445  29.428947 29.403505 29.378155 29.352915\n",
      " 29.32778  29.3028   29.277962 29.253277 29.22875  29.204397 29.180199\n",
      " 29.15617  29.13228  29.10857  29.084986 29.061546 29.03823  29.015038\n",
      " 28.991953 28.969002 28.946144 28.923405 28.900772 28.87825  28.855833\n",
      " 28.833529 28.811325 28.789238 28.767263 28.745405 28.72366  28.702034\n",
      " 28.68053  28.659128 28.637848 28.61668  28.595629 28.574684 28.553854\n",
      " 28.533129 28.512522 28.492016 28.47161  28.451317 28.431126 28.411045\n",
      " 28.391062 28.371191 28.351427 28.33177  28.312212 28.292776 28.273434\n",
      " 28.25419  28.235065 28.21603  28.197102 28.178284 28.15954  28.140903\n",
      " 28.122362 28.103922 28.08558  28.067324 28.049154 28.031096 28.013134\n",
      " 27.995255 27.977463 27.959768 27.942173 27.924654 27.907257 27.889927]\n"
     ]
    }
   ],
   "source": [
    "latest_data = scaler.transform(df[['temperature (degF)']].values)[-window_size:].reshape((1, window_size, 1))\n",
    "predicted_temperatures_normalized = []\n",
    "\n",
    "# Recursive prediction\n",
    "for _ in range(window_size):\n",
    "    # Predict the next step\n",
    "    next_step_normalized = model.predict(latest_data)\n",
    "    \n",
    "    # Store the normalized prediction\n",
    "    predicted_temperatures_normalized.append(next_step_normalized[0, 0])\n",
    "    \n",
    "    # Update the input sequence with the new prediction\n",
    "    # This moves the window one step forward by inserting the predicted value\n",
    "    latest_data = np.roll(latest_data, -1, axis=1)\n",
    "    latest_data[0, -1, 0] = next_step_normalized[0, 0]\n",
    "\n",
    "# Convert normalized predictions back to the original scale (degrees Fahrenheit)\n",
    "predicted_temperatures = scaler.inverse_transform(np.array(predicted_temperatures_normalized).reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"Predicted temperatures for the next 7 days (168 hours):\")\n",
    "print(predicted_temperatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 20:34:50.872465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.876265: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.913531: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node lstm_12_input}}]]\n",
      "2024-03-16 20:34:50.945406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node lstm_12_input}}]]\n",
      "2024-03-16 20:34:50.950729: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.955439: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node lstm_12_input}}]]\n",
      "2024-03-16 20:34:50.959664: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.964056: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node lstm_12_input}}]]\n",
      "2024-03-16 20:34:50.967521: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.970409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.976395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:50.980155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:51.002057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node lstm_12_input}}]]\n",
      "2024-03-16 20:34:51.008475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:51.011973: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:51.071874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2024-03-16 20:34:51.075514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2024-03-16 20:34:51.078660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:51.082115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,168,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-16 20:34:51.230148: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_lstm_12_input' with dtype float and shape [?,168,1]\n",
      "\t [[{{node serving_default_lstm_12_input}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/tempModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/tempModel/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model/tempModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model('model/tempModel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
